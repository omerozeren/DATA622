---
title: "DATA 622 - Test 1"
author: "OMER OZEREN"
output:
  html_document:
    highlight: tango
    theme: journal
    toc: yes
    toc_depth: 5
    toc_float: yes
---

```{r echo=FALSE, include=FALSE}
library(class)
library(pROC)
library(ROCR)
library(caret)
library(e1071)
library(naivebayes)
library(MASS)
library(mltools)
library(knitr)
library(dplyr)
library(tidyr)
```

## A)

Run Bagging (ipred package)   

* sample with replacement

* estimate metrics for a model

* repeat as many times as specied and report the average



### Load the Data

```{r}
df <- read.table("~/Documents/GitHub/DATA622/data.txt",header = T,sep=',')
df$label <- ifelse(df$label =="BLACK",1,0)
df$y <- as.numeric(df$y)
df$X <- as.factor(df$X)
```

### Split Data into Train (70%) and Test data(30%)  

```{r}
set.seed(42)
split_df <- createDataPartition(df$label, p = .70, list = FALSE)
df_train <- df[split_df,]
df_test <- df[-split_df,]
```

### Model Performance Estimator
```{r}
estimate_model_performance <- function(y_true, y_pred, model_name){
  cm <- confusionMatrix(table(y_true, y_pred))
  cm_table <- cm$table
  tpr <- cm_table[[1]] / (cm_table[[1]] + cm_table[[4]])
  fnr <- 1 - tpr
  fpr <- cm_table[[3]] / (cm_table[[3]] + cm_table[[4]])
  tnr <- 1 - fpr
  accuracy <- cm$overall[[1]]
  for_auc <- prediction(c(y_pred), y_true)
  auc <- performance(for_auc, "auc")
  auc <- auc@y.values[[1]]
  return(data.frame(Algo = model_name, AUC = auc, ACCURACY = accuracy, TPR = tpr, FPR = fpr, TNR = tnr, FNR = fnr))
}
```


### NB Model Building

```{r}
nb_model<-naiveBayes(df_train$label~.,data=df_train)
nb_testpred<-predict(nb_model,df_test,type='raw')
nb_testclass<-unlist(apply(round(nb_testpred),1,which.max))-1
nb_table<-table(df_test$label, nb_testclass)
nb_cm<-caret::confusionMatrix(nb_table)
```

### Estimate NB model test data () performance

```{r}
estimate_model_performance(df_test$label,nb_testclass,'NB')
```


### Bagging Methodology - NB Model

I'm going to create a function for boostrap purposes first.I'm going to run NB model  50 times and store the performance metrics for each data boostrap.

```{r}
apply_bootstrap_data <- function(data, proportion = 0.7, sample_with_replacement = TRUE){
  observation <- round(nrow(data) * proportion, 0)
  return(data[sample(nrow(data), observation, replace = sample_with_replacement),])
}
```

```{r}
the_bags <- list()
for (i in 1:50){
  sample <- apply_bootstrap_data(df_train)
  the_bags[[i]] <- sample
  
  # Train the Naive Bayes Model
  nb_model <- naiveBayes(sample$label ~ ., data = sample)
  y_pred <- predict(nb_model, df_test,type='raw')
  y_pred_class<-unlist(apply(round(y_pred),1,which.max))-1
  ## Evaluate the capacity to learn
  performance <- estimate_model_performance(df_test$label, y_pred_class, paste("NB Bag", i))
  if(exists("performance_table")){
    performance_table <- rbind(performance_table, performance)
  } else {
    performance_table <- performance
  }
}

``` 
### The Mean of Boostrap NM model 

```{r}
mean(performance_table$ACCURACY)
```

### The Variance of Boostrap NM model 

```{r}
var(performance_table$ACCURACY)
```

Now, I'm going to try KNN stand alone and boostrap methodology

### KNN Model Building

```{r}
knn_y_true<- knn(df_train[1:2],df_test[1:2], cl = df_train$label, k = 5)
knn_testclass<-knn_y_true
knn_table<-table(df_test$label, knn_testclass)
knn_cm<-caret::confusionMatrix(knn_table)
knn_cm
```

### Bagging Methodology - KNN Model

I'm going to create a function for boostrap purposes first.I'm going to run KNN model  50 times and store the performance metrics for each data boostrap.

```{r}
apply_bootstrap_data <- function(data, proportion = 0.7, sample_with_replacement = TRUE){
  observation <- round(nrow(data) * proportion, 0)
  return(data[sample(nrow(data), observation, replace = sample_with_replacement),])
}
```

```{r}
the_bags <- list()
for (i in 1:50){
  sample <- apply_bootstrap_data(df_train)
  the_bags[[i]] <- sample
  
  # Train the Naive Bayes Model
  nb_model <- naiveBayes(sample$label ~ ., data = sample)
  y_pred <- knn(sample[1:2],df_test[1:2], cl = sample$label, k = 5)
  y_pred_class<-y_pred
  ## Evaluate the capacity to learn
  performance <- estimate_model_performance(df_test$label, y_pred_class, paste("KNN Bag", i))
  if(exists("performance_table_knn")){
    performance_table_knn <- rbind(performance_table_knn, performance)
  } else {
    performance_table_knn <- performance
  }
}

``` 
### The Mean of Boostrap KNN model 

```{r}
mean(performance_table_knn$ACCURACY)
```

### The Variance of Boostrap KNN model 

```{r}
var(performance_table_knn$ACCURACY)
```
